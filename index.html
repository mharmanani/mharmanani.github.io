<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head>
  <meta charset="utf-8">
  <title>Mohamed Harmanani</title>

  <meta name="author" content="Mohamed Harmanani">
  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <link href="vendor/css/bootstrap.min.css" rel="stylesheet">
  <link href="vendor/css/font-awesome.min.css" rel="stylesheet">
  <link href="vendor/css/academicons.min.css" rel="stylesheet">
  <link href="vendor/pygments/default.css" rel="stylesheet">
  <link href="css/bamos.css" rel="stylesheet">
  <link href="css/styles.css" rel="stylesheet">
  <link href="css/sharingbuttons.css" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet" type="text/css">
  <script async="" src="https://www.google-analytics.com/analytics.js"></script><script src="vendor/js/jquery.min.js"></script>

  <link rel="apple-touch-icon" sizes="180x180" href="images/icn/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="images/icn/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="images/icn/favicon-16x16.png">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVFSVQ6MXT"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NVFSVQ6MXT');
  </script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>
	<div class="navbar navbar-default navbar-fixed-top">
		<div class="container">
			<div class="row">
				<div class="col-md-10 col-md-offset-1" style="width: 100%; margin-left: 0 !important;">
					<div class="navbar-header">
						  <a href="/" class="navbar-brand">
                  <div>
                      <!--<img src="images/me-face.jpeg" class="img-circle"> !-->
                      Mohamed Harmanani
                  </div>
              </a>
						<button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
						</button>
					</div>
					<div class="navbar-collapse collapse" id="navbar-main">
            <ul class="nav navbar-nav"><!--
              <li>
                <a href="/blog.html">
                  <i class="fa fa-fountain-pen"></i>Blog</a>
							</li>
							<li>
								<a href="/miscellanous">Misc.</a>-->
							</li>
						</ul>
						<ul class="nav navbar-nav navbar-right" style="font-size: 1.5em">
							<li>
								<a href="http://github.com/mharmanani" target="_blank">
									<i class="fa-brands fa-github"></i></a>
							</li>
							<li>
								<a href="http://linkedin.com/in/mharmanani" target="_blank">
									<i class="fa-brands fa-linkedin-in"></i></a>
							</li>
              <li>
								<a href="https://scholar.google.com/citations?hl=en&user=dNDG5CgAAAAJ" target="_blank">
									<i class="ai ai-google-scholar"></i></a>
							</li>
						</ul>
					</div>
				</div>
			</div>
		</div>
	</div>

<div class="container">
  <div class="row">
    <div class="col-md-6 col-md-offset-1 vcenter idxHdr">
      <div class="name-main" style="font-size: 2.5em; color: #4582ec; font-weight: bold; padding-bottom: 0.3em;">
        Mohamed Harmanani 
      </div>
      <div style="font-size: 1.2em;">
        Graduate Researcher, Deep Learning/Medical Imaging
      </div>
      <div style="font-size: 1.2em; padding-top: 0.3em;">
        <a href="https://vectorinstitute.ai">Vector Institute</a>, Toronto, Canada
      </div>
      <div style="font-size: 1.2em; padding-top: 0.3em;">
        <a href="https://medi.cs.queensu.ca"> Med-<i>i</i> Lab</a>, Queen's University
      </div>
      <br>

      <div style="padding: 0.3em; background-color: #4582ec; display: inline-block; border-radius: 4px; font-size: 1.2em;">
        <a href="data/cv.pdf" target="_blank" style="text-decoration: none;">
          <i style="color: white" class="fa fa-download"></i>
        </a>
        <!--<a href="https://github.com" target="_blank" style="text-decoration: none;">
          <i style="color: white;" class="fa fa-code-fork"></i>
        </a>-->
        <a href="data/cv.pdf" target="_blank" style="color: white; text-decoration: none;">CV</a>
      </div>

      <ul class="list-inline idxIcons" style="font-size: 1.9em; margin-top: 0.5em;">
        <li>
          <a href="http://github.com/mharmanani" target="_blank">
            <i class="fa-brands fa-github"></i></a>
        </li>
        <li>
          <a href="mailto:mohamed.harmanani@queensu.ca" target="_blank">
            <i class="fa fa-envelope"></i></a>
        </li>
        <li>
          <a href="https://scholar.google.com/citations?hl=en&user=dNDG5CgAAAAJ" target="_blank">
          <i class="ai ai-google-scholar"></i></a>
        </li>
        <li>
          <a href="https://www.researchgate.net/profile/Mohamed-Harmanani" target="_blank">
            <i class="ai ai-researchgate"></i></a>
        </li>
        <li>
          <a href="http://www.linkedin.com/in/mharmanani" target="_blank">
            <i class="fa-brands fa-linkedin-in"></i></a>
        </li>
      </ul>
    </div>
    <div class="col-md-2 vcenter idxHdr">
      <img src="images/me3.jpeg" style="border-radius: 20px; margin: 10px; max-width: 340px;">
    </div>
  </div>

  <div class="row">
    <div class="col-md-12">
<hr>

<p align="justify"> 
  I am a MSc candidate at Queen's University as well as a Research Assistant in the <a href="https://medi.cs.queensu.ca">Medical Informatics (Med-<i>i</i>)</a> laboratory, advised by Dr. Parvin Mousavi. 
  My main research interests are in computer vision, deep learning, and medical imaging. More specifically, my research focuses on using deep learning to detect prostate cancer in real-time during ultrasound-guided biopsy procedures. 
  I am a recipient of the Robert Sutherland Fellowship at Queen's and the <a href="https://medicreate.cs.queensu.ca/">NSERC MediCREATE</a> training award. 
</p>
<p><br></p>

<h2 id="-education"><i class="fa fa-landmark"></i> Education</h2>

<table class="table table-hover">
  <tbody><tr>
    <td>
      <strong>MSc. in Artificial Intelligence</strong>, <em>Queen's University</em>

      <br>
        <p style="margin-top:-1em;margin-bottom:0em">
        <!--<br> Thesis: <em><a href="" target="_blank">Thesis</a></em>-->
        <br> Advisor: <a href="https://vectorinstitute.ai/team/parvin-mousavi/" target="_blank">Parvin Mousavi</a>
        </p>
    </td>
    <td class="col-md-2" style="text-align:right;">2022&nbsp;-&nbsp;Present</td>
  </tr>
  <tr>
    <td>
      <strong>HBSc. in Computer Science</strong> & Philosophy, <em>University of Toronto</em>
      <br>
    </td>
    <td class="col-md-2" style="text-align:right;">2016&nbsp;-&nbsp;2021</td>
  </tr>
</tbody></table>

<h2 id="-previous-positions"><i class="fa fa-desktop"></i> Experience </h2>
<table class="table table-hover">
<tbody>

<tr>
  <td style="padding-right:0;">
<p style="margin: 0"><strong>Machine Learning Student Researcher</strong>, <em>Vector Institute</em></p>
  </td>
  <td class="col-md-2" style="text-align:right; padding-left:0;">2023&nbsp;-&nbsp;Present</td>
</tr>

<tr>
  <td style="padding-right:0;">
<p style="margin: 0"><strong>Graduate Research Assistant</strong>, <em>Queen's University</em><span style="color:grey;font-size:1.3rem;margin: 0">
(with <a href="https://vectorinstitute.ai/team/parvin-mousavi/" target="_blank">Parvin Mousavi</a> on AI/ML for healthcare)
</span></p>
  </td>
  <td class="col-md-2" style="text-align:right; padding-left:0;">2022&nbsp;-&nbsp;Present</td>
</tr>

<tr>
  <td style="padding-right:0;">
<p style="margin: 0"><strong>Data Scientist</strong>, <em>Flinks</em>, Montréal
<span style="color:grey;font-size:1.3rem;margin: 0">
(PyTorch, BERT, NLP)
</span></p>
  </td>
  <td class="col-md-2" style="text-align:right; padding-left:0;">2021&nbsp;-&nbsp;2022</td>
</tr>

<tr>
  <td style="padding-right:0;">
<p style="margin: 0"><strong>Research Intern</strong>, <em>University of Toronto</em><span style="color:grey;font-size:1.3rem;margin: 0">
(with <a href="https://www.cs.toronto.edu/~lczhang/" target="_blank">Lisa Zhang</a> on ML and NLP)
</span></p>
  </td>
  <td class="col-md-2" style="text-align:right; padding-left:0;">2021</td>
</tr>

<tr>
  <td style="padding-right:0;">
<p style="margin: 0"><strong>Research Assistant</strong>, <em>University of Toronto</em><span style="color:grey;font-size:1.3rem;margin: 0">
(with <a href="https://www.plant-epigenetics.com" target="_blank">Katharina Braeutigam</a> on bioinformatics)
</span></p>
  </td>
  <td class="col-md-2" style="text-align:right; padding-left:0;">2020&nbsp;-&nbsp;2021</td>
</tr>

<tr>
  <td style="padding-right:0;">
<p style="margin: 0"><strong>Software Engineer</strong>, <em>Venngage</em>, Toronto
<span style="color:grey;font-size:1.3rem;margin: 0">
(TypeScript & React.js development)
</span></p>
  </td>
  <td class="col-md-2" style="text-align:right; padding-left:0;">2019&nbsp;-&nbsp;2020</td>
</tr>
</tbody></table>

<h2 id="-publications"><i class="fa fa-scroll"></i> Publications & Preprints</h2>

<!-- [<a href="https://github.com/bamos/cv/blob/master/publications/all.bib">BibTeX</a>] -->
<!--<p>Representative publications that I am a primary author on are -->
<!--<span style="background-color: #ffffd0">highlighted.</span>-->
<!--<br>-->
<!--[<a href="https://scholar.google.com/citations?user=d8gdZR4AAAAJ">Google Scholar</a>; x+ citations, h-index: y+]</p> -->

<!--<h2>2022</h2>-->
<table class="table table-hover">

<tbody class="publications-body">

  <tr><td></td></tr>
  <tr>
    <td>
      <img class="pub-img" src="images/publications/ipcai24/lensepro1 copy.png" width="269">
    </td>
    <td>

      <div class="pub-title">
        <strong>LensePro: Label Noise-Tolerant Prototype-Based Network for Improving Cancer Detection in Prostate Ultrasound with Limited Annotations</strong><br>
      </div>
      
      <div class="pub-authors">
        MNN. To, F. Fooladgar*, PFR. Wilson*, <strong>M. Harmanani</strong>*, M. Gilany, S. Sojoudi, A. Jamzad, S. Chang, P. Black, <br>P. Mousavi<sup>†</sup>, P Abolmaesumi<sup>†</sup>
      </div>

      <div class="pub-venue">
        <i> Int J of Computer Assisted  Radiology and Surgery (IJCARS), 2024 </i><br>
      </div>

      <div class="pub-links">
        [<a href="javascript: none" onclick="$(&quot;#abstract_ipcai24&quot;).toggle()">abs</a>]
        [<a href="https://link.springer.com/article/10.1007/s11548-024-03104-3" target="_blank">paper</a>]
      </div>
      
      <div id="abstract_ipcai24" class="pub-abs" style="text-align: justify; display: none">
        <p>This study presents LensePro, a unified method that not only excels in label efficiency but also demonstrates robustness against label noise and OOD data. LensePro comprises two key stages: first, self-supervised learning to extract high-quality feature representations from abundant unlabeled TRUS data, and second, label noise-tolerant prototype-based learning to classify the extracted features.
        </p>
      </div>	
    </td>
  </tr>

  <tr><td></td></tr>
  <tr>
    <td>
      <img class="pub-img" src="images/publications/ijcars24/fig_heatmaps_2 copy.png" width="269">
    </td>
    <td>
      <div class="pub-title">
        <strong>Towards Confident Prostate Cancer Detection using Ultrasound: A Multi-Center Study</strong><br>
      </div>
  
      <div class="pub-authors">
        PFR. Wilson, <strong>M. Harmanani</strong>, MNN. To, M. Gilany, A. Jamzad, F. Fooladgar, B. Wodlinger, P. Abolmaesumi, P. Mousavi <br>
      </div>
  
      <div class="pub-venue">
        <i> Int J of Computer Assisted  Radiology and Surgery (IJCARS), 2024 (to appear) </i><br>
      </div>
  
      <div class="pub-links">
        [<a href="javascript: none" onclick="$(&quot;#abstract_ijcars24&quot;).toggle()">abs</a>]
        [<span style="color: black;" target="_blank">paper</span>]
      </div>
  
      <div id="abstract_ijcars24" class="pub-abs" style="text-align: justify; display: none">
        <p>
          Prostate ultrasound data is highly heterogeneous due to variability in tissue
          types and the cancer appearance in images, making the development of robust
          models that can generalize to new patients and clinical settings, challenging.
          A viable model requires not only accurate cancer predictions but also effective
          uncertainty calibration, i.e. understanding when the predictions are likely to be
          correct. Previous studies on uncertainty calibration for PCa detection often rely
          on limited or single center datasets which may not adequately capture real-world
          data variability. We aim to establish realistic benchmarks for PCa detection using
          a multi-centre, diverse dataset to better assess the clinical utility of this tool.
        </p>
      </div>
    </td>
  </tr>

  <tr><td></td></tr>
  <tr>
    <td class="col-md-3">
      <img class="pub-img" src="images/publications/vit_v_cct_002.png" width="269">
    </td>
    <td>

      <div class="pub-title">
        <strong>Benchmarking Image Transformers for Prostate Cancer Detection from Ultrasound Data</strong><br>
      </div>
      
      <div class="pub-authors">
        <strong>M. Harmanani</strong>, PFR. Wilson, F. Fooladgar, A. Jamzad, M. Gilany, MNN. To, B. Wodlinger, P. Abolmaesumi, P. Mousavi <br>
      </div>

      <div class="pub-venue">
        <i> SPIE Medical Imaging 2024 </i><br>
      </div>

      <div class="pub-links">
        [<a href="javascript: none" onclick="$(&quot;#abstract_spie24&quot;).toggle()">abs</a>]
        [<a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12928/1292815/Benchmarking-image-transformers-for-prostate-cancer-detection-from-ultrasound-data/10.1117/12.3006049.short#_=_" target="_blank">paper</a>]
        [<a href="https://arxiv.org/abs/2403.18233" target="_blank">arXiv</a>]
      </div>
      
      <div id="abstract_spie24" class="pub-abs" style="text-align: justify; display: none">
        <p>
          We present a detailed study of several Image Transformer
          architectures for both ROI-scale and multi-scale classification, and a comparison of the performance of CNNs
          and Transformers for ultrasound-based prostate cancer classification. We evaluate 3 vision 
          transformers on ROI-scale cancer classification then use the strongest model to tune a multi-scale classifier using
          multi-objective learning. We compare our results in both settings to a baseline convolutional architecture typically used in computer vision tasks. We evaluate all our models using nested k-fold cross-validation.
          Our core-wise multi-objective model achieves a 77.9% AUROC, a sensitivity of 75.9%, and a specificity of 66.3%,
          a considerable improvement over baseline ROI-scale classification.
        </p>
      </div>	
    </td>
  </tr>


  <tr><td></td></tr>
  <tr>
    <td class="col-md-3">
      <img class="pub-img" src="images/publications/spark_remake.png" width="269">
    </td>
    <td>

      <div class="pub-title">
        <strong>Modelling the Spread of COVID-19 in Indoor Spaces using Probabilistic Automated Planning</strong><br>
      </div>

      <div class="pub-authors">
        <strong>M. Harmanani</strong> <br>
      </div>
      
      <div class="pub-venue">
        <i>ICAPS 2023 Scheduling and Planning Applications woRKshop (SPARK 2023) </i> <br>
      </div>

      <div class="pub-links">
        [<a href="javascript: none" onclick="$(&quot;#abstract_spark23&quot;).toggle()">abs</a>]
        [<a href="https://arxiv.org/abs/2308.08190" target="_blank">arXiv</a>]
      </div>

      <div id="abstract_spark23" class="pub-abs" style="text-align: justify; display: none">
        <p>In this work, we explore a novel approach based on probabilistic planning and dynamic graph analysis to model the spread of 
          COVID-19 in indoor spaces. We also endow the planner with means to control the spread of the disease trough non-pharmaceutical interventions (NPIs) 
          such as mandating masks, vaccines, capacity limits, and social distancing. We demonstrate that the use of automated probabilistic planning is 
          effective in predicting the amount of infections that are likely to occur in shared spaces, and that they are capable of designing competent 
          interventions to limit the spread of the disease.
        </p>
      </div>	
    </td>
  </tr>


  <tr><td></td></tr>
  <tr>
    <td class="col-md-3">
      <img class="pub-img" src="images/publications/sigcse22.png" 
        style="border: 0.5px solid #050938; padding: 0;" width="269">
    </td>
    <td>
      
      <div class="pub-title">
        <strong>Using Deep Learning to Localize Errors in Student Code Submissions</strong><br>
      </div>

      <div class="pub-authors">
        S. Fujimori, <strong>M. Harmanani</strong>, O. Siddiqui, and L. Zhang<br>
      </div>

      <div class="pub-venue">
        <i>ACM Technical Symposium on Computer Science Education (SIGCSE 2022)</i>
      </div>

      <div class="pub-links">
        [<a href="javascript: none" onclick="$(&quot;#abstract_sigsce22&quot;).toggle()">abs</a>]
        [<a href="https://doi.org/10.1145/3478432.3499048" target="_blank">paper</a>]
        [<a href="data/sigcse22/slides.pdf" target="_blank">slides</a>]
      </div>

      <div id="abstract_sigsce22" class="pub-abs" style="text-align: justify; display: none">
        <p>We explore RNN and CodeBERT deep learning models that highlight errors in student submissions to Python coding problems. 
          We find that a standard automatic metric like AUC does not correspond well to human evaluation, 
          and that the scale of the benefits of transfer learning and pre-training are only seen when using human evaluation. </p>
      </div>	
    </td>
  </tr>


</tbody></table>


<h2 id="-teaching"><i class="fa fa-book-open-reader"></i> Teaching</h2>
<table class="table table-hover">
  <tbody>

    <tr>
      <td class="col-md-1">W2024</td>
      <td><strong>Head Teaching Assistant</strong>, Algorithms I (CISC 365) at Queen's</td>
    </tr>

    <tr>
      <td class="col-md-1">F2023</td>
      <td><strong>Teaching Assistant</strong>, Neural &amp; Genetic Computing (CISC 452) at Queen's</td>
    </tr>

    <tr>
      <td class="col-md-1">W2023</td>
      <td><strong>Teaching Assistant</strong>, Intro to Data Analytics (CISC 151) at Queen's</td>
    </tr>
</tbody></table>


<h2 id="-honors--awards"><i class="fa fa-award"></i> Honors &amp; Awards</h2>
<table class="table table-hover">
<tbody>
<tr>
<td>
  <div style="float: right;">2023</div>
  <div>Vector Institute Research Grant</div>
  <div style="color:grey;font-size:1.3rem;margin: 0">Awarded to Vector researchers to support research in AI/ML</div>
</td>
</tr>
<tr>
<td> 
  <div style="float: right;">2023</div>
  <div> NSERC MediCREATE Central Line Challenge, 2nd Place </div>
  <div style="color:grey;font-size:1.3rem;margin: 0">Developed a deep learning model for (1) surgical tool detection and (2) task identification in surgical videos</div>
</td>
</tr>
<tr>
  <td>
  <div style="float: right">2022</div>
  <div>
    Robert Sutherland Fellowship
  </div>
  <div style="color:grey;font-size:1.3rem;margin: 0">Awarded to distinguished students at Queen's belonging to a minority group</div>
  </td>
  <!-- <td class='col-md-2' style='text-align:right;'>2019</td> -->
</tr>
<tr>
  <td>
  <div style="float: right">2022</div>
  <div>
    NSERC MediCREATE Training Award
  </div>
  <div style="color:grey;font-size:1.3rem;margin: 0">Awarded to students in the NSERC CREATE training program in medical informatics</div>
  </td>
  <!-- <td class='col-md-2' style='text-align:right;'>2019</td> -->
</tr>
  <tr>
  <td>
  <div style="float: right">2021</div>
  <div>
    University of Toronto Undergraduate Research Grant
  </div>
  <div style="color:grey;font-size:1.3rem;margin: 0">Awarded to students in good academic standing to present at a conference</div>
  </td>
  <!-- <td class='col-md-2' style='text-align:right;'>2019</td> -->
</tr>
<tr>
  <td>
  <div style="float: right">2021</div>
  <div>
    University of Toronto Maths & Computer Science Honour Roll
  </div>
  <div style="color:grey;font-size:1.3rem;margin: 0">Awarded to students with a grade of 90% or greater in 3+ Math & Computer Science courses at the University of Toronto in 2020-2021</div>
  </td>
  <!-- <td class='col-md-2' style='text-align:right;'>2016&nbsp;-&nbsp;2019</td> -->
</tr>
<tr>
  <td>
  <div style="float: right">2021</div>
  <div>
    Excellence 300 Award in Philosophy
  </div>
  <div style="color:grey;font-size:1.3rem;margin: 0">Awarded to the student with the highest mark in a 300-level Philosophy class</div>
  </td>
  <!-- <td class='col-md-2' style='text-align:right;'>2016&nbsp;-&nbsp;2019</td> -->
</tr>
<tr>
  <td>
  <div style="float: right">2016</div>
  <div>
    University of Toronto Entrance Award
  </div>
  <div style="color:grey;font-size:1.3rem;margin: 0">Awarded to distinguished students admitted into the Faculty of Arts & Science </div>
  </td>
  <!-- <td class='col-md-2' style='text-align:right;'>2016&nbsp;-&nbsp;2019</td> -->
</tr>
</tbody></table>

<h2 id="-skills"><i class="fa fa-wrench"></i> Skills</h2>
<table class="table table-hover">
<tbody><tr>
  <td class="col-md-2"><b>Programming</b></td>
  <td> Python, SQL, Java, R, TypeScript, C, C++, Haskell, Make </td>
</tr>
<tr>
  <td class="col-md-2"><b>Frameworks</b></td>
  <td> PyTorch, scikit-learn, Keras, NumPy, Pandas, SciPy, TensorFlow, Seaborn, React, Node.js </td>
</tr>
<tr>
  <td class="col-md-2"><b>Toolbox</b></td>
  <td> BigQuery, Google Dataflow, GCP, AWS (S3, SageMaker), Linux, DVC, vim, git, zsh, Jupyter </td>
</tr>
</tbody></table>

<hr>

<p>Last updated on 2024-04-15 </p>


    </div>
</div>

<div id="forest-ext-shadow-host"></div></body></html>
